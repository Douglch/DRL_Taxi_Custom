{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bTojaNNIVW0U",
    "outputId": "1df22af2-d526-4648-a88b-8b80b1761954"
   },
   "outputs": [],
   "source": [
    "# !pip install -r https://raw.githubusercontent.com/huggingface/deep-rl-class/main/notebooks/unit2/requirements-unit2.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-22T06:19:51.172211Z",
     "start_time": "2023-05-22T06:19:49.458663Z"
    },
    "id": "M4JhN0TXVK7d"
   },
   "outputs": [],
   "source": [
    "# %%capture\n",
    "# !sudo apt-get update\n",
    "# !apt install python-opengl ffmpeg xvfb\n",
    "# !pip3 install pyvirtualdisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-22T06:19:52.405059Z",
     "start_time": "2023-05-22T06:19:52.287953Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bp1mcuKuVMfJ",
    "outputId": "272c8541-6ebf-4ec8-88a6-ec68b121ad48"
   },
   "outputs": [],
   "source": [
    "# Virtual display (NOTE: WILL NOT WORK ON WINDOWS)\n",
    "# from pyvirtualdisplay import Display\n",
    "\n",
    "# virtual_display = Display(visible=0, size=(1400, 900))\n",
    "# virtual_display.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-22T06:20:44.042660Z",
     "start_time": "2023-05-22T06:20:43.905686Z"
    },
    "id": "DR3__sdeVaoc"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gymnasium as gym\n",
    "import random\n",
    "import imageio\n",
    "import os\n",
    "import tqdm\n",
    "\n",
    "import pickle\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-22T06:20:47.445724Z",
     "start_time": "2023-05-22T06:20:47.413729Z"
    },
    "id": "MkNhpRLYVa-E"
   },
   "outputs": [],
   "source": [
    "env = gym.make(\"Taxi-v3\", render_mode=\"human\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-22T06:20:48.915459Z",
     "start_time": "2023-05-22T06:20:48.897924Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xoAAthcj8Y0H",
    "outputId": "cd9d0ed6-08a0-427a-c569-8780aa39e7a6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_____OBSERVATION SPACE_____ \n",
      "\n",
      "Observation Space Discrete(16)\n",
      "Sample observation 9\n"
     ]
    }
   ],
   "source": [
    "print(\"_____OBSERVATION SPACE_____ \\n\")\n",
    "print(\"Observation Space\", env.observation_space)\n",
    "print(\"Sample observation\", env.observation_space.sample()) # Get a random observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-22T06:20:51.764268Z",
     "start_time": "2023-05-22T06:20:51.748590Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "C1yIUwGv8fiP",
    "outputId": "a63a0b79-2fc5-4ad6-c83a-7fd93d1f32e6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " _____ACTION SPACE_____ \n",
      "\n",
      "Action Space Shape 4\n",
      "Action Space Sample 1\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n _____ACTION SPACE_____ \\n\")\n",
    "print(\"Action Space Shape\", env.action_space.n)\n",
    "print(\"Action Space Sample\", env.action_space.sample()) # Take a random action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-22T06:20:53.330689Z",
     "start_time": "2023-05-22T06:20:53.314860Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rB88qHF9801u",
    "outputId": "98cf2ba5-40d6-4bda-ede9-bcddb2e87ea6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are  16  possible states\n",
      "There are  4  possible actions\n"
     ]
    }
   ],
   "source": [
    "state_space = env.observation_space.n\n",
    "print(\"There are \", state_space, \" possible states\")\n",
    "\n",
    "action_space = env.action_space.n\n",
    "print(\"There are \", action_space, \" possible actions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-22T06:20:54.210831Z",
     "start_time": "2023-05-22T06:20:54.197182Z"
    },
    "id": "OIxVw9g69Ff7"
   },
   "outputs": [],
   "source": [
    "# Let's create our Qtable of size (state_space, action_space) and initialized each values at 0 using np.zeros. np.zeros needs a tuple (a,b)\n",
    "def initialize_q_table(state_space, action_space):\n",
    "  Qtable = np.zeros((state_space, action_space))\n",
    "  return Qtable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-22T06:20:55.697410Z",
     "start_time": "2023-05-22T06:20:55.690763Z"
    },
    "id": "Qj2oJVzK9MFb"
   },
   "outputs": [],
   "source": [
    "# Create our Q table with state_size rows and action_size columns (500x6)\n",
    "Qtable_taxi = initialize_q_table(state_space, action_space)\n",
    "print(Qtable_taxi)\n",
    "print(\"Q-table shape: \", Qtable_taxi .shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-22T06:20:56.288755Z",
     "start_time": "2023-05-22T06:20:56.281986Z"
    },
    "id": "f10zaWS8-UzS"
   },
   "outputs": [],
   "source": [
    "def greedy_policy(Qtable, state):\n",
    "  # Exploitation: take the action with the highest state, action value\n",
    "  action = np.argmax(Qtable[state][:])\n",
    "  return action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-22T06:20:56.779985Z",
     "start_time": "2023-05-22T06:20:56.764155Z"
    },
    "id": "xd_-ZCsh_ENR"
   },
   "outputs": [],
   "source": [
    "def epsilon_greedy_policy(Qtable, state, epsilon):\n",
    "  # Randomly generate a number between 0 and 1\n",
    "  random_int = random.uniform(0,1)\n",
    "  # if random_int > greater than epsilon --> exploitation\n",
    "  if random_int > epsilon:\n",
    "    # Take the action with the highest value given a state\n",
    "    # np.argmax can be useful here\n",
    "    action = greedy_policy(Qtable, state)\n",
    "  # else --> exploration\n",
    "  else:\n",
    "    action = env.action_space.sample()\n",
    "  \n",
    "  return action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-22T06:20:57.397878Z",
     "start_time": "2023-05-22T06:20:57.381431Z"
    },
    "id": "MUCUYJweCFzz"
   },
   "outputs": [],
   "source": [
    "# Training parameters\n",
    "n_training_episodes = 25000   # Total training episodes\n",
    "learning_rate = 0.7           # Learning rate\n",
    "\n",
    "# Evaluation parameters\n",
    "n_eval_episodes = 100        # Total number of test episodes\n",
    "\n",
    "# DO NOT MODIFY EVAL_SEED\n",
    "eval_seed = [16,54,165,177,191,191,120,80,149,178,48,38,6,125,174,73,50,172,100,148,146,6,25,40,68,148,49,167,9,97,164,176,61,7,54,55,\n",
    " 161,131,184,51,170,12,120,113,95,126,51,98,36,135,54,82,45,95,89,59,95,124,9,113,58,85,51,134,121,169,105,21,30,11,50,65,12,43,82,145,152,97,106,55,31,85,38,\n",
    " 112,102,168,123,97,21,83,158,26,80,63,5,81,32,11,28,148] # Evaluation seed, this ensures that all classmates agents are trained on the same taxi starting position\n",
    "                                                          # Each seed has a specific starting state\n",
    "\n",
    "# Environment parameters\n",
    "env_id = \"Taxi-v3\"           # Name of the environment\n",
    "max_steps = 99               # Max steps per episode\n",
    "gamma = 0.95                 # Discounting rate\n",
    "\n",
    "# Exploration parameters\n",
    "max_epsilon = 1.0             # Exploration probability at start\n",
    "min_epsilon = 0.05           # Minimum exploration probability \n",
    "decay_rate = 0.005            # Exponential decay rate for exploration prob\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-22T06:20:58.689658Z",
     "start_time": "2023-05-22T06:20:58.678353Z"
    },
    "id": "ErSJPF12CYd5"
   },
   "outputs": [],
   "source": [
    "def train(n_training_episodes, min_epsilon, max_epsilon, decay_rate, env, max_steps, Qtable):\n",
    "  for episode in tqdm(range(n_training_episodes)):\n",
    "    # Reduce epsilon (because we need less and less exploration)\n",
    "    epsilon = min_epsilon + (max_epsilon - min_epsilon)*np.exp(-decay_rate*episode)\n",
    "    # Reset the environment\n",
    "    state, info = env.reset()\n",
    "    step = 0\n",
    "    terminated = False\n",
    "    truncated = False\n",
    "\n",
    "    # repeat\n",
    "    for step in range(max_steps):\n",
    "      env.render()\n",
    "      # Choose the action At using epsilon greedy policy\n",
    "      action = epsilon_greedy_policy(Qtable, state, epsilon)\n",
    "\n",
    "      # Take action At and observe Rt+1 and St+1\n",
    "      # Take the action (a) and observe the outcome state(s') and reward (r)\n",
    "      new_state, reward, terminated, truncated, info = env.step(action)\n",
    "\n",
    "      # Update Q(s,a):= Q(s,a) + lr [R(s,a) + gamma * max Q(s',a') - Q(s,a)]\n",
    "      Qtable[state][action] = Qtable[state][action] + learning_rate * (reward + gamma * np.max(Qtable[new_state]) - Qtable[state][action])   \n",
    "\n",
    "      # If terminated or truncated finish the episode\n",
    "      if terminated or truncated:\n",
    "        break\n",
    "      \n",
    "      # Our next state is the new state\n",
    "      state = new_state\n",
    "  return Qtable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-22T06:21:00.222597Z",
     "start_time": "2023-05-22T06:21:00.006747Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "aad329805ba04863a809f67a1b460957",
      "628312ff4ce542e39348da6b41cacd6a",
      "c853135099134a16ae74d9d0b4bc08ee",
      "fb14eea0f26343b191d9de6d45705ed7",
      "33dad8d8fb3542119d6ec37207405b2f",
      "19bd4974018d445b82d3fe2bd4fe5149",
      "7207170b51304cd4918361b89f0dc574",
      "d8e79ee995a24af5958d7e32f6b27564",
      "ac009cde77e24df9b9c76f36a29421b0",
      "a0ac9fed3d8b4474b8057767f7cc0b28",
      "2938d31d4d704237890b289d3f7c9d5e"
     ]
    },
    "id": "oD-VMEizENsc",
    "outputId": "d75e6a90-8152-49f9-8590-836cb80c506e"
   },
   "outputs": [],
   "source": [
    "Qtable_taxi = train(n_training_episodes, min_epsilon, max_epsilon, decay_rate, env, max_steps, Qtable_taxi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-22T06:21:09.545502Z",
     "start_time": "2023-05-22T06:21:09.529635Z"
    },
    "id": "f_Vi0BxSEOG7"
   },
   "outputs": [],
   "source": [
    "Qtable_taxi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-22T06:21:10.295609Z",
     "start_time": "2023-05-22T06:21:10.276441Z"
    },
    "id": "aY-HJBrxFSaE"
   },
   "outputs": [],
   "source": [
    "def evaluate_agent(env, max_steps, n_eval_episodes, Q, seed):\n",
    "  \"\"\"\n",
    "  Evaluate the agent for ``n_eval_episodes`` episodes and returns average reward and std of reward.\n",
    "  :param env: The evaluation environment\n",
    "  :param n_eval_episodes: Number of episode to evaluate the agent\n",
    "  :param Q: The Q-table\n",
    "  :param seed: The evaluation seed array (for taxi-v3)\n",
    "  \"\"\"\n",
    "  episode_rewards = []\n",
    "  for episode in tqdm(range(n_eval_episodes)):\n",
    "    if seed:\n",
    "      state, info = env.reset(seed=seed[episode])\n",
    "    else:\n",
    "      state, info = env.reset()\n",
    "    step = 0\n",
    "    truncated = False\n",
    "    terminated = False\n",
    "    total_rewards_ep = 0\n",
    "    \n",
    "    for step in range(max_steps):\n",
    "      # Take the action (index) that have the maximum expected future reward given that state\n",
    "      action = greedy_policy(Q, state)\n",
    "      new_state, reward, terminated, truncated, info = env.step(action)\n",
    "      total_rewards_ep += reward\n",
    "        \n",
    "      if terminated or truncated:\n",
    "        break\n",
    "      state = new_state\n",
    "    episode_rewards.append(total_rewards_ep)\n",
    "  mean_reward = np.mean(episode_rewards)\n",
    "  std_reward = np.std(episode_rewards)\n",
    "\n",
    "  return mean_reward, std_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-22T06:21:11.031938Z",
     "start_time": "2023-05-22T06:21:10.917601Z"
    },
    "id": "hftkrVIRHSTy"
   },
   "outputs": [],
   "source": [
    "# Usually, you should have a mean reward of 1.0\n",
    "mean_reward, std_reward = evaluate_agent(env, max_steps, n_eval_episodes, Qtable_taxi, eval_seed)\n",
    "print(f\"Mean_reward={mean_reward:.2f} +/- {std_reward:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-22T06:21:11.382468Z",
     "start_time": "2023-05-22T06:21:11.334273Z"
    },
    "id": "cHe86-g6HTO_"
   },
   "outputs": [],
   "source": [
    "from huggingface_hub import HfApi, snapshot_download\n",
    "from huggingface_hub.repocard import metadata_eval_result, metadata_save\n",
    "\n",
    "from pathlib import Path\n",
    "import datetime\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-22T06:21:11.883274Z",
     "start_time": "2023-05-22T06:21:11.872704Z"
    },
    "id": "t-nYHolvHjsX"
   },
   "outputs": [],
   "source": [
    "# def record_video(env, Qtable, out_directory, fps=1):\n",
    "#   \"\"\"\n",
    "#   Generate a replay video of the agent\n",
    "#   :param env\n",
    "#   :param Qtable: Qtable of our agent\n",
    "#   :param out_directory\n",
    "#   :param fps: how many frame per seconds (with taxi-v3 and frozenlake-v1 we use 1)\n",
    "#   \"\"\"\n",
    "#   images = []  \n",
    "#   terminated = False\n",
    "#   truncated = False\n",
    "#   state, info = env.reset(seed=random.randint(0,500))\n",
    "#   img = env.render()\n",
    "#   images.append(img)\n",
    "#   while not terminated or truncated:\n",
    "#     # Take the action (index) that have the maximum expected future reward given that state\n",
    "#     action = np.argmax(Qtable[state][:])\n",
    "#     state, reward, terminated, truncated, info = env.step(action) # We directly put next_state = state for recording logic\n",
    "#     img = env.render()\n",
    "#     images.append(img)\n",
    "#   imageio.mimsave(out_directory, [np.array(img) for i, img in enumerate(images)], fps=fps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-22T06:21:12.441756Z",
     "start_time": "2023-05-22T06:21:12.409687Z"
    },
    "id": "5qkQ6konHk_g"
   },
   "outputs": [],
   "source": [
    "# def push_to_hub(\n",
    "#     repo_id, model, env, video_fps=1, local_repo_path=\"hub\"\n",
    "# ):\n",
    "#     \"\"\"\n",
    "#     Evaluate, Generate a video and Upload a model to Hugging Face Hub.\n",
    "#     This method does the complete pipeline:\n",
    "#     - It evaluates the model\n",
    "#     - It generates the model card\n",
    "#     - It generates a replay video of the agent\n",
    "#     - It pushes everything to the Hub\n",
    "\n",
    "#     :param repo_id: repo_id: id of the model repository from the Hugging Face Hub\n",
    "#     :param env\n",
    "#     :param video_fps: how many frame per seconds to record our video replay \n",
    "#     (with taxi-v3 and frozenlake-v1 we use 1)\n",
    "#     :param local_repo_path: where the local repository is\n",
    "#     \"\"\"\n",
    "#     _, repo_name = repo_id.split(\"/\")\n",
    "\n",
    "#     eval_env = env\n",
    "#     api = HfApi()\n",
    "\n",
    "#     # Step 1: Create the repo\n",
    "#     repo_url = api.create_repo(\n",
    "#         repo_id=repo_id,\n",
    "#         exist_ok=True,\n",
    "#     )\n",
    "\n",
    "#     # Step 2: Download files\n",
    "#     repo_local_path = Path(snapshot_download(repo_id=repo_id))\n",
    "\n",
    "#     # Step 3: Save the model\n",
    "#     if env.spec.kwargs.get(\"map_name\"):\n",
    "#         model[\"map_name\"] = env.spec.kwargs.get(\"map_name\")\n",
    "#         if env.spec.kwargs.get(\"is_slippery\", \"\") == False:\n",
    "#             model[\"slippery\"] = False\n",
    "\n",
    "#     # Pickle the model\n",
    "#     with open((repo_local_path) / \"q-learning.pkl\", \"wb\") as f:\n",
    "#         pickle.dump(model, f)\n",
    "\n",
    "#     # Step 4: Evaluate the model and build JSON with evaluation metrics\n",
    "#     mean_reward, std_reward = evaluate_agent(\n",
    "#         eval_env, model[\"max_steps\"], model[\"n_eval_episodes\"], model[\"qtable\"], model[\"eval_seed\"]\n",
    "#     )\n",
    "\n",
    "#     evaluate_data = {\n",
    "#         \"env_id\": model[\"env_id\"],\n",
    "#         \"mean_reward\": mean_reward,\n",
    "#         \"n_eval_episodes\": model[\"n_eval_episodes\"],\n",
    "#         \"eval_datetime\": datetime.datetime.now().isoformat()\n",
    "#     }\n",
    "\n",
    "#     # Write a JSON file called \"results.json\" that will contain the\n",
    "#     # evaluation results\n",
    "#     with open(repo_local_path / \"results.json\", \"w\") as outfile:\n",
    "#         json.dump(evaluate_data, outfile)\n",
    "\n",
    "#     # Step 5: Create the model card\n",
    "#     env_name = model[\"env_id\"]\n",
    "#     if env.spec.kwargs.get(\"map_name\"):\n",
    "#         env_name += \"-\" + env.spec.kwargs.get(\"map_name\")\n",
    "\n",
    "#     if env.spec.kwargs.get(\"is_slippery\", \"\") == False:\n",
    "#         env_name += \"-\" + \"no_slippery\"\n",
    "\n",
    "#     metadata = {}\n",
    "#     metadata[\"tags\"] = [env_name, \"q-learning\", \"reinforcement-learning\", \"custom-implementation\"]\n",
    "\n",
    "#     # Add metrics\n",
    "#     eval = metadata_eval_result(\n",
    "#         model_pretty_name=repo_name,\n",
    "#         task_pretty_name=\"reinforcement-learning\",\n",
    "#         task_id=\"reinforcement-learning\",\n",
    "#         metrics_pretty_name=\"mean_reward\",\n",
    "#         metrics_id=\"mean_reward\",\n",
    "#         metrics_value=f\"{mean_reward:.2f} +/- {std_reward:.2f}\",\n",
    "#         dataset_pretty_name=env_name,\n",
    "#         dataset_id=env_name,\n",
    "#     )\n",
    "\n",
    "#     # Merges both dictionaries\n",
    "#     metadata = {**metadata, **eval}\n",
    "\n",
    "#     model_card = f\"\"\"\n",
    "#   # **Q-Learning** Agent playing1 **{env_id}**\n",
    "#   This is a trained model of a **Q-Learning** agent playing **{env_id}** .\n",
    "\n",
    "#   ## Usage\n",
    "\n",
    "#   ```python\n",
    "  \n",
    "#   model = load_from_hub(repo_id=\"{repo_id}\", filename=\"q-learning.pkl\")\n",
    "\n",
    "#   # Don't forget to check if you need to add additional attributes (is_slippery=False etc)\n",
    "#   env = gym.make(model[\"env_id\"])\n",
    "#   ```\n",
    "#   \"\"\"\n",
    "\n",
    "#     evaluate_agent(env, model[\"max_steps\"], model[\"n_eval_episodes\"], model[\"qtable\"], model[\"eval_seed\"])\n",
    "  \n",
    "#     readme_path = repo_local_path / \"README.md\"\n",
    "#     readme = \"\"\n",
    "#     print(readme_path.exists())\n",
    "#     if readme_path.exists():\n",
    "#         with readme_path.open(\"r\", encoding=\"utf8\") as f:\n",
    "#             readme = f.read()\n",
    "#     else:\n",
    "#         readme = model_card\n",
    "\n",
    "#     with readme_path.open(\"w\", encoding=\"utf-8\") as f:\n",
    "#         f.write(readme)\n",
    "\n",
    "#     # Save our metrics to Readme metadata\n",
    "#     metadata_save(readme_path, metadata)\n",
    "\n",
    "#     # Step 6: Record a video\n",
    "#     video_path = repo_local_path / \"replay.mp4\"\n",
    "#     record_video(env, model[\"qtable\"], video_path, video_fps)\n",
    "\n",
    "#     # Step 7. Push everything to the Hub\n",
    "#     api.upload_folder(\n",
    "#         repo_id=repo_id,\n",
    "#         folder_path=repo_local_path,\n",
    "#         path_in_repo=\".\",\n",
    "#     )\n",
    "\n",
    "#     print(\"Your model is pushed to the Hub. You can view your model here: \", repo_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-22T06:21:13.372913Z",
     "start_time": "2023-05-22T06:21:13.361769Z"
    },
    "id": "ekis--OMHvOx"
   },
   "outputs": [],
   "source": [
    "model = {\n",
    "    \"env_id\": env_id,\n",
    "    \"max_steps\": max_steps,\n",
    "    \"n_training_episodes\": n_training_episodes,\n",
    "    \"n_eval_episodes\": n_eval_episodes,\n",
    "    \"eval_seed\": eval_seed,\n",
    "\n",
    "    \"learning_rate\": learning_rate,\n",
    "    \"gamma\": gamma,\n",
    "\n",
    "    \"max_epsilon\": max_epsilon,\n",
    "    \"min_epsilon\": min_epsilon,\n",
    "    \"decay_rate\": decay_rate,\n",
    "\n",
    "    \"qtable\": Qtable_taxi\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-22T06:21:13.809668Z",
     "start_time": "2023-05-22T06:21:13.785499Z"
    },
    "id": "eLoeoHtQH73o"
   },
   "outputs": [],
   "source": [
    "model"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "19bd4974018d445b82d3fe2bd4fe5149": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2938d31d4d704237890b289d3f7c9d5e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "33dad8d8fb3542119d6ec37207405b2f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "628312ff4ce542e39348da6b41cacd6a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_19bd4974018d445b82d3fe2bd4fe5149",
      "placeholder": "​",
      "style": "IPY_MODEL_7207170b51304cd4918361b89f0dc574",
      "value": "  1%"
     }
    },
    "7207170b51304cd4918361b89f0dc574": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a0ac9fed3d8b4474b8057767f7cc0b28": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "aad329805ba04863a809f67a1b460957": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_628312ff4ce542e39348da6b41cacd6a",
       "IPY_MODEL_c853135099134a16ae74d9d0b4bc08ee",
       "IPY_MODEL_fb14eea0f26343b191d9de6d45705ed7"
      ],
      "layout": "IPY_MODEL_33dad8d8fb3542119d6ec37207405b2f"
     }
    },
    "ac009cde77e24df9b9c76f36a29421b0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "c853135099134a16ae74d9d0b4bc08ee": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d8e79ee995a24af5958d7e32f6b27564",
      "max": 10000,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_ac009cde77e24df9b9c76f36a29421b0",
      "value": 116
     }
    },
    "d8e79ee995a24af5958d7e32f6b27564": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fb14eea0f26343b191d9de6d45705ed7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a0ac9fed3d8b4474b8057767f7cc0b28",
      "placeholder": "​",
      "style": "IPY_MODEL_2938d31d4d704237890b289d3f7c9d5e",
      "value": " 115/10000 [04:36&lt;8:28:01,  3.08s/it]"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
